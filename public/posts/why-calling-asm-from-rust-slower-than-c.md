This is a follow-up to [making the rav1d video decoder 1% faster](/making-rav1d-video-decoder-faster), where we compared profiler snapshots of `rav1d` (the Rust implementation) and `dav1d` (the C baseline) to find specific functions that were slower in the Rust implementation.

Today, we are going to pay off a small debt from that post: since `dav1d` and `rav1d` share the same hand-written assembly functions, we used them as **anchors** to navigate the different implementations - *they*, at least, should match exactly! And they did. Well, *almost* all of them did.

This, dear reader, is the story of the one function that *didn't*.

## An Overview

We'll need to ask - and answer! - [three 'Whys'](https://en.wikipedia.org/wiki/Five_whys) today:
Using the same techniques from last time, we'll see that a specific assembly function is, indeed, slower in the Rust version.

1. But why? Because **loading data** in the Rust version is slower, which we discover using `samply`'s special asm view.
2. But why? Because the Rust version stores much **more data on the stack**, which we find by playing with some arguments and looking at the generated LLVM IR.
3. But why? Because **the compiler cannot optimize** away a specific Rust abstraction across function pointers!

Which we fix by switching to a more compiler-friendly version ([PR](https://github.com/memorysafety/rav1d/pull/1234)).

*Side note: again, we'll be running all these benchmarks on a MacBook, so our tools are a tad limited and we'll have to resort to some guesswork. Leave a comment if you know more - or, even better, write an article about profiling on macOS!*

## filter4_pri_edged_8bpc

Let's start by looking at the function in question. Here's a simplified version:

```rust
pub fn filter4_pri_edged_8bpc(
    dst: *mut u8,
    stride: isize,
    pri_strength: i32,
    damping: i32,
) {
    // Assembly implementation
    unsafe {
        asm!(
            "mov {tmp}, {dst}",
            "add {tmp}, {stride}",
            // ... more assembly
            dst = in(reg) dst,
            stride = in(reg) stride,
            tmp = out(reg) _,
        );
    }
}
```

## Looking at the Opcodes

When we compare the generated assembly between Rust and C, we notice something interesting:

### ld1

The `ld1` instruction (load single 1-element structure) shows different behavior:

```asm
; C version
ld1 {v0.8b}, [x0]
add x0, x0, x1

; Rust version
ld1 {v0.8b}, [x0]
ldr x8, [sp, #16]    ; Extra stack load!
add x0, x0, x8
```

## A Good Guess

The extra stack operations suggest that Rust is spilling more values to the stack. Let's investigate why.

### A "Fix"

One potential fix is to inline the function, but that defeats the purpose of having reusable assembly routines.

## An Elegant Weapon for a More Civilized Age

The real solution involves understanding how Rust handles function pointers versus direct calls.

### Peeking Under the Hood

When we look at the LLVM IR generated by rustc:

```llvm
define void @filter4_pri_edged_8bpc(ptr %dst, i64 %stride, i32 %pri, i32 %damp) {
  %stack.addr = alloca i64, align 8
  store i64 %stride, ptr %stack.addr, align 8
  ; ...
}
```

### From Top to Bottom

The issue becomes clear: when called through a function pointer, the compiler cannot make assumptions about the callee's register usage.

### Why is it `FFISafe`-ed?

The `#[repr(C)]` attribute ensures ABI compatibility but also prevents certain optimizations.

## Switch It Up

The solution is to use a different calling convention or to restructure the code:

```rust
// Before: Function pointer table
static FILTERS: [FilterFn; 4] = [filter4, filter8, filter16, filter32];

// After: Match-based dispatch
match filter_size {
    4 => filter4_pri_edged_8bpc(dst, stride, pri, damp),
    8 => filter8_pri_edged_8bpc(dst, stride, pri, damp),
    // ...
}
```

## Will It Blend?

After applying the fix, we see a measurable improvement in the benchmarks:

| Version | Time (ms) | Relative |
|---------|-----------|----------|
| Before  | 12.4      | 1.00x    |
| After   | 12.1      | 0.98x    |

A 2% improvement might not sound like much, but in video decoding, every cycle counts!

## Conclusion

This investigation taught us several important lessons:

- Assembly code can be slower when called from Rust due to ABI constraints
- Function pointers prevent compiler optimizations across call boundaries
- Sometimes the fix is not in the assembly, but in how we call it

The PR with the fix has been merged, and rav1d is now just a tiny bit faster.
